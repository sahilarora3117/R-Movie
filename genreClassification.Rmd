---
title: "Analysis and Prediction of Movie Performance"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 19BCE1349 Anish Hemant There
## 19BCE1260 Sahil Arora
## 19BCE1366 Puvvadi Harsha Vardhan

***

The question of what makes a movie good has been asked for a while now. Quantifying the parameters on which a movie’s performance is one of the ways to predict how a movie would perform amongst others. Movie reviews are important because if they have a significant effect on the consumer thought processes, they can be used not only as a marketing tool by film production studios, but also as a predictor as to how a film will perform financially. We heavily rely on other people’s opinion and analysis to choose which movie to watch. The parameters on which the movie’s performance rely upon is dependent on duration of the movie, the critics reviews, the genre the movie is based on etc. 
We aim to analyze the data and find the parameters which affect a movie’s performance. This will also help us understand how movies have changed throughout the years and across the world. We can also map those changes to historical incidents which would help us understand the consequence and affects the cinema has in our life.

***

### Loading the required libraries

```{r}
library(ggplot2)
library(dplyr)
library(Hmisc)
library(psych)
library(tidyr)
```

### Reading the dataset

```{r}
movie <- read.csv('movie_metadata.csv', stringsAsFactors = F)
str(movie)
```

### Dimension of the dataset

```{r}
dim(movie)
```

### Summary of the dataset

```{r}
summary(movie)
```

***

### Exploratory Analysis

```{r}
ggplot(aes(x = num_critic_for_reviews), data = movie) + geom_histogram(bins = 20, color = 'white') + ggtitle('Histogram of Number of reviews')
summary(movie$num_critic_for_reviews)
```

***

According to this plot most movies have around critic reviews in the range of 50-200 

***

```{r}
ggplot(aes(x = imdb_score), data = movie) + geom_histogram(bins = 20, color = 'white') + ggtitle('Histogram of Scores')
```

***

Most frequent IMDB scores for movies are in the range 5.0 to 7.5 

***

```{r}
ggplot(aes(x = title_year), data = movie) + geom_histogram(color='white') +
  ggtitle('Histogram of Title Year')
```

***

This plot tells us the number of movies produced each year. Most of the movies in this dataset are produced after the year 2000

***

```{r}
boxplot(imdb_score ~ title_year, data=movie, col='indianred')
title("IMDB score vs Title year")
```

***

This plot tells us the variation of the IMDB scores over the years. People are ready to give lower scores to movies and this also tells us about the quality of the movies that are being produced. Half a century ago there were only a few players in the movie production market but right now, with the increase of this medium we have seen lots of new producers and directors coming into this market which has led to gradual decrease in the quality of the product with relation to that product.

***

### Plot of top 10 countries vs number of movies produced

```{r}
country_group <- group_by(movie, country)
movie_by_country <- summarise(country_group,
                               mean_score = mean(imdb_score),
                               n = n())
aa = movie_by_country[order(-movie_by_country$n), ] %>%
        head(10)
ggplot(aes(x = country, y = n, fill = country), data = aa) + geom_bar(stat = 'identity') + theme(legend.position = "none", axis.text=element_text(size=6)) +
  coord_flip() + ggtitle('Countries vs Number of Movies')
```

***

The Highest number of movies is produced by the USA

***

```{r}
ggplot(aes(x = country, y = mean_score, fill = country), data = movie_by_country) + geom_bar(stat = 'identity') + theme(legend.position = "none", axis.text=element_text(size=7)) +
  coord_flip() + ggtitle('Countries vs IMDB Scores')
```

***

This is a plot of mean IMDB score of each country. Even though USA produced the highest number of movies, Libya has the highest average score. The difference in the average scores is in between 4 and 8.

***

### Data Cleaning

```{r}
movie$imdb_score <- as.numeric(impute(movie$imdb_score, mean))
movie$num_critic_for_reviews <- as.numeric(impute(movie$num_critic_for_reviews, mean))
movie$duration <- as.numeric(impute(movie$duration, mean))
movie$director_facebook_likes <- as.numeric(impute(movie$director_facebook_likes, mean))
movie$actor_3_facebook_likes <- as.numeric(impute(movie$actor_3_facebook_likes, mean))
movie$actor_1_facebook_likes <- as.numeric(impute(movie$actor_1_facebook_likes, mean))
movie$gross <- as.numeric(impute(movie$gross, mean))
movie$cast_total_facebook_likes <- as.numeric(impute(movie$cast_total_facebook_likes, mean))
movie$facenumber_in_poster <- as.numeric(impute(movie$facenumber_in_poster, mean))
movie$budget <- as.numeric(impute(movie$budget, mean))
movie$title_year <- as.numeric(impute(movie$title_year, median))
movie$actor_2_facebook_likes <- as.numeric(impute(movie$actor_2_facebook_likes, mean))
movie$aspect_ratio <- as.numeric(impute(movie$aspect_ratio, mean))

```

### Separating genres into different columns

```{r}
movie <- movie %>%
  mutate(genres=gsub("[-]","",genres))
movie = movie %>%
  mutate(row = row_number()) %>%
    separate_rows(genres, sep = '\\|') %>%
      pivot_wider(names_from = genres, values_from = genres, values_fn = function(x) 1, values_fill = 0) %>%
        select(-row)

movie = na.omit(movie)

```

```{r}
genres = subset(movie, select = c(28:53))

sum = mapply(sum, genres[,]) %>%
        sort(decreasing = TRUE)
```

```{r}
genre_count = genres %>%
                gather() %>%
                  group_by(key) %>%
                    summarise(value = sum(value==1))
```

```{r}
ggplot(genre_count, aes(x=key, y=value, fill=key)) + geom_bar(stat="identity") + theme(legend.position = "none", axis.text=element_text(size=6)) + coord_flip() + ylab("Count") + xlab("Genre") + ggtitle('Genre Counts')
```

***

Drama is the most produced genre with a count of 2586

***

### Top 20 highest-rated movie

```{r}
movie[order(-movie$imdb_score), ] %>%
  select(movie_title) %>%
    head(20)
```

### Top 20 lowest-rated movie

```{r}
movie[order(movie$imdb_score), ] %>%
  select(movie_title) %>%
    head(20)
```

### Average movie duration 

```{r}
mean(movie$duration)
```

### Count of movies based on language

```{r}
lang = movie %>%
        group_by(language) %>%
          summarise(n=n()) 
lang[order(-lang$n), ]
```

### Multiple Linear Regression - Variable Selection


```{r}
movie_sub <- subset(movie, select = c(3, 4, 5, 8, 9, 13, 15, 22, 27, 28:53, 25))
movie_sub
```

***

Only selecting numeric values for the regression model

***

### Construct the model

```{r}
set.seed(123)
train_size <- 0.8 
train_index <- sample.int(length(movie_sub$imdb_score), length(movie_sub$imdb_score) * train_size)
train_sample <- movie_sub[train_index,]
test_sample <- movie_sub[-train_index,]
```

### Fit the model 

```{r}
fit <- lm(imdb_score ~ num_critic_for_reviews + duration +    director_facebook_likes + actor_1_facebook_likes + gross + cast_total_facebook_likes + facenumber_in_poster + budget + movie_facebook_likes + Action + Adventure + Fantasy +  Thriller + Documentary + Romance + Animation + Comedy + Family + Musical +  Mystery + Western + Drama + History + Sport + Crime + Horror + War + Biography + Music + News + Short, data=train_sample)
summary(fit) 
```

***

Model with all the variables

***

```{r}
fit <- lm(imdb_score ~ num_critic_for_reviews + duration +  director_facebook_likes + actor_1_facebook_likes +  cast_total_facebook_likes + facenumber_in_poster + Action + Thriller + Documentary + Animation + Comedy + Family + Mystery + Drama + Crime + Horror + War + Biography + Music, data=train_sample)
summary(fit) 
```

***

Model with only the significant variables. The median for the residual error is close to 0 and the absolute minimum and maximum values are also close which means that the average residual error is approximately 0. The adjusted R-squared value is 0.29 which means the model can explain only 29% of the variation. 

***

```{r}
plot(fit)
```

***

From the residuals vs fitted graph we can see that there are quite a few outliers at the end and overall the dispersion is uneven. From the Normal Q-Q plot we can see that there is a huge deviation at the start.
 
***

```{r}
train_sample$pred_score <- predict(fit, newdata = subset(train_sample, select=c(imdb_score, num_critic_for_reviews, duration, director_facebook_likes, actor_1_facebook_likes, cast_total_facebook_likes, facenumber_in_poster, movie_facebook_likes, Action ,Adventure, Fantasy,Thriller, Documentary ,Romance ,Animation ,Comedy ,Family ,Musical ,Mystery, Western ,Drama ,History ,Sport ,Crime ,Horror,War ,Biography ,Music, News ,Short)))
test_sample$pred_score <- predict(fit, newdata = subset(test_sample, select=c(imdb_score, num_critic_for_reviews, duration, director_facebook_likes, actor_1_facebook_likes, cast_total_facebook_likes, facenumber_in_poster, movie_facebook_likes, Action ,Adventure, Fantasy,Thriller, Documentary ,Romance ,Animation ,Comedy ,Family ,Musical ,Mystery, Western ,Drama ,History ,Sport ,Crime ,Horror,War ,Biography ,Music, News ,Short)))
```

### Evaluating on train set

```{r}
train_corr <- round(cor(train_sample$pred_score, train_sample$imdb_score), 2)
train_rmse <- round(sqrt(mean((train_sample$pred_score - train_sample$imdb_score)^2)), 2)
train_mae <- round(mean(abs(train_sample$pred_score - train_sample$imdb_score)), 2)
c(train_corr^2, train_rmse, train_mae)
```

***

The predicted and the actual scores are not highly correlated.
RMSE value is high which means the model doesn't fit the data well
MAE is also high which is bad as the predicted imdb score values lie in 0-10 range

***

### Evaluating on test set

```{r}
test_rmse <- round(sqrt(mean((test_sample$pred_score - test_sample$imdb_score)^2)), 2)
test_mae <- round(mean(abs(test_sample$pred_score - test_sample$imdb_score)), 2)
c(test_rmse, test_mae)
```

***

Test set also has high RMSE and MAE values 

***

### Decision Tree

```{r}
library(rpart)
library(rpart.plot)
```

```{r}
movie_sub_dectre <- subset(movie, select = c(3, 4, 5, 8, 9, 13, 15, 22, 27, 28:53))
movie_sub_dectre$imdb_cat <- as.numeric(cut2(movie_sub$imdb_score, g=3))

movie_sub_dectre$imdb_cat <- factor(x=movie_sub_dectre$imdb_cat, levels=sort(unique(movie_sub_dectre$imdb_cat)), labels = c("Low", "Medium", "High"))
movie_sub_dectre
```

***

Distributing the scores into 3 different categories Low, Medium and High

***

```{r}
set.seed(123)
train_size <- 0.8 
train_index <- sample.int(length(movie_sub_dectre$imdb_cat), length(movie_sub_dectre$imdb_cat) * train_size)
train_sample <- movie_sub_dectre[train_index,]
test_sample <- movie_sub_dectre[-train_index,]
```

```{r}
fit <- rpart(imdb_cat ~ num_critic_for_reviews + duration + budget + director_facebook_likes + actor_1_facebook_likes + cast_total_facebook_likes + facenumber_in_poster + movie_facebook_likes + Action + Adventure + Fantasy +  Thriller + Documentary + Romance + Animation + Comedy + Family + Musical +  Mystery + Western + Drama + History + Sport + Crime + Horror + War + Biography + Music + News + Short, data=train_sample, method = 'class')
rpart.plot(fit)
```

```{r}
predicted <- predict(fit, test_sample, type = 'class')
table_mat <- table(test_sample$imdb_cat, predicted)
table_mat
```

```{r}
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
print(paste('Accuracy for test', accuracy_Test))
```

***

Accuracy of 54% was achieved on the test data using the decision tree classifier

***

## Naive bayees using geners only

```{r}
library(e1071)
```

```{r}
genre_sub <- subset(movie_sub_dectre, select = c(10:35, 36))

index <- sample(1 : nrow(genre_sub), round(0.75 * nrow(genre_sub)))

train_cl <- genre_sub[index, ]
test_cl <- genre_sub[-index, ]

set.seed(120)  
classifier_cl <- naiveBayes(imdb_cat ~ ., data = train_cl)
classifier_cl
```

```{r}
y_pred <- predict(classifier_cl, newdata = test_cl)

cm <- table(test_cl$imdb_cat, y_pred)
cm
print(paste("Accuracy", sum(diag(cm)) / sum(cm)))
```

***

Accuracy of 41% was achieved with Naive bayees classifier

***

### KNN

```{r}
library(caTools)
library(class)
```

```{r}
set.seed(123)
train_size <- 0.8 
train_index <- sample.int(length(movie_sub_dectre$imdb_cat), length(movie_sub_dectre$imdb_cat) * train_size)
train_sample <- movie_sub_dectre[train_index,]
test_sample <- movie_sub_dectre[-train_index,]

train_sample <- na.omit(train_sample)
test_sample <- na.omit(test_sample)

train_cl <- train_sample[, 1:35]
test_cl <- test_sample[, 1:35]

classifier_knn <- knn(train = train_cl,
                      test = test_cl,
                      cl = train_sample$imdb_cat,
                      k =100)
cm <- table(test_sample$imdb_cat, classifier_knn)
cm
misClassError <- mean(classifier_knn != test_sample$imdb_cat)
print(paste('Accuracy =', 1-misClassError))
```

***

Accuracy of 42% was achieved with KNN classifier

***


## Neural networks

```{r}
library(neuralnet)
```

```{r}
movie_sub_dectre$imdb_num <- factor(x=movie_sub_dectre$imdb_cat, levels=sort(unique(movie_sub_dectre$imdb_cat)), labels = c(1,2,3))
movie_sub_dectre$imdb_num = as.numeric(movie_sub_dectre$imdb_num)

movie_idk = select(movie_sub_dectre, -c("imdb_cat"))
```

```{r}
index <- sample(1 : nrow(movie_idk),
                round(0.75 * nrow(movie_idk)))
maxs <- apply(movie_idk, 2, max)
mins <- apply(movie_idk, 2, min)
scaled <- as.data.frame(scale(movie_idk,
                              center = mins,
                              scale = maxs - mins))
aa = movie_idk[index, ]
ab = movie_idk[-index, ]

train_ <- scaled[index, ]
test_ <- scaled[-index, ]

train_$imdb_num = as.numeric(as.factor(aa$imdb_num))
test_$imdb_num = as.numeric(as.factor(ab$imdb_num))
```

```{r}
NN = neuralnet(imdb_num ~ num_critic_for_reviews + duration + director_facebook_likes + actor_1_facebook_likes + cast_total_facebook_likes + facenumber_in_poster + movie_facebook_likes, data=train_, hidden = 2)
plot(NN)
```

![](nn.png)

```{r}
d = round(NN$net.result[[1]])
cm = table(d, train_$imdb_num)
cm
```

```{r}
print(paste("Accuracy", sum(diag(cm)) / sum(cm)))
```

***

Accuracy of 40% was achieved using perceptron based neural network with 2 hidden layers

***

### Conclusion

We were able to successfully analyze and interpret the IMDB movie dataset. With the help of some well written research papers, we were able to work upon interpreting the results on a higher level. We used multiple models to predict the scores which includes KNN, Neural networks, Regression, Naive Bayees, Decision trees. We also did exploratory analysis on the dataset which helped us come to conclusion on the overall trends of the movie market.


